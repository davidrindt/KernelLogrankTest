---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(survival)
# library(condSURV)
# library(JM)
# library(dplyr)
# library(survminer)
# library(clustcurv)
library(psych)
library(ggplot2)
```

This downloads the data, and edits it a bit. In partifcular loan status is transformed, variables are turned into dates, the year 2006 is selected etc. This is from an online course on survival data. 

```{r}
web <- "https://s3.amazonaws.com/udacity-hosted-downloads/ud651/prosperLoanData.csv"
loan <- read.csv(web)

# Remove duplicates by LoanKey
loan_nd <- loan[!duplicated(loan$LoanKey), ]

# removing LoanStatus no needed
sel_status  <- loan_nd$LoanStatus %in% c("Completed", "Current",
                                         "ChargedOff", "Defaulted",
                                         "Cancelled")
loan_filtered <- loan_nd[sel_status, ]

# creating status variable for censoring
loan_filtered$status <- ifelse(
  loan_filtered$LoanStatus == "Defaulted" |
    loan_filtered$LoanStatus == "Chargedoff",  1, 0)

# adding the final date to "current" status
head(levels(loan_filtered$ClosedDate))
## [1] ""                    "2005-11-25 00:00:00" "2005-11-29 00:00:00"
## [4] "2005-11-30 00:00:00" "2005-12-08 00:00:00" "2005-12-28 00:00:00"
levels(loan_filtered$ClosedDate)[1] <- "2014-11-03 00:00:00"

# creating the time-to-event variable
loan_filtered$start <- as.Date(loan_filtered$LoanOriginationDate)
loan_filtered$end <- as.Date(loan_filtered$ClosedDate)
loan_filtered$time <- as.numeric(difftime(loan_filtered$end, loan_filtered$start, units = "days"))

# there is an error in the data (time to event less than 0)
loan_filtered <- loan_filtered[-loan_filtered$time < 0, ]

# just considering a year of loans creation
ii <- format(as.Date(loan_filtered$LoanOriginationDate),'%Y') %in% c("2006")
loan_filtered <- loan_filtered[ii, ]

loan_filtered$LoanOriginalAmount2 <-  loan_filtered$LoanOriginalAmount/10000


# write.csv(to_save_data, 'loan_data_2006_cleaned')

```

```{r}
# describe(loan_filtered)
```


I did not really analyse the entire dataset much. You'd have to filter it quite carefully. Many NA's are present. Also many ' ' empty strings are present.

```{r}
# print(sum(!complete.cases(loan_data_2006[,"BorrowerState"])))
```

```{r}
# # print(colSums(is.na(loan_data_2006)))
# loan_data_2006 = loan_data_2006_cleaned[, colSums(is.na(loan_data_2006_cleaned)) == 0]
# # loan_data_2006 = loan_data_2006[, colSums(is.na(loan_data_2006)) == 0]
# print(colSums(loan_data_2006 == '') == 0)
```

Select the subset of the data:


```{r}
subset_data = loan_filtered[, c("IsBorrowerHomeowner", "LoanOriginalAmount2", 'time', 'status')]
```


Fit a cox model without including spline terms on all data (4954 loans, of which 1373 are observed events. I.e. 28 % of the events is observed.). This results in significant effect. Overall p-value is p=4.358e-06. 

```{r}
mfit <- coxph(Surv(time, status) ~ IsBorrowerHomeowner + LoanOriginalAmount2, data=subset_data)
mfit
```


Now we fit again a model on all the data, but we include spline terms for the LoanOriginalAmount2. With a spline of order 3 the overall p-value is p=9e-09. The plot seems to suggest medium sized loans have the least risk to default. 


```{r}
mfit <- coxph(Surv(time, status) ~ IsBorrowerHomeowner + pspline(LoanOriginalAmount2, 3) , data=subset_data)
mfit
termplot(mfit, term=2, se=TRUE, col.term=1, col.se=1)

ptemp <- termplot(mfit, se=TRUE, plot=FALSE)
```

We now plot the two KM curves for the binary variable IsBorrowerHomeowner. Actually the CPH assumption seems quite fine, except for a couple of observations at the end. 


```{r}
km_trt_fit <- survfit(Surv(time, status) ~ IsBorrowerHomeowner, data=subset_data)
# autoplot(km_trt_fit)
```

Now we do the analysis for smaller sample sizes:


```{r}

mfit <- coxph(Surv(time, status) ~ IsBorrowerHomeowner + LoanOriginalAmount2 , data=subset_data[sample(nrow(subset_data), 1000),])
mfit
```


And finally we average the p-value obtained on the subsamples over 100 runs. In Python I get
{'cph_test': 0.13403668092069104, 'gaucon': 0.04515484515484516, 'gaugau': 0.0073426573426573424}

```{r}
p_value_sum = 0
for (i in 0:100){
  mfit <- coxph(Surv(time, status) ~ IsBorrowerHomeowner + LoanOriginalAmount2 , data=subset_data[sample(nrow(subset_data), 1000),])
  p_value = summary(mfit)$sctest['pvalue']
  p_value_sum = p_value_sum + p_value
}
print(p_value_sum/100)

```


When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
